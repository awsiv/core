<html lang="en">
<head>
<title>Scale and Scalability</title>
<meta http-equiv="Content-Type" content="text/html">
<meta name="description" content="Scale and Scalability">
<meta name="generator" content="makeinfo 4.13">
<link title="Top" rel="top" href="#Top">
<link href="http://www.gnu.org/software/texinfo/" rel="generator-home" title="Texinfo Homepage">
<meta http-equiv="Content-Style-Type" content="text/css">
<style type="text/css"><!--
  pre.display { font-family:inherit }
  pre.format  { font-family:inherit }
  pre.smalldisplay { font-family:inherit; font-size:smaller }
  pre.smallformat  { font-family:inherit; font-size:smaller }
  pre.smallexample { font-size:smaller }
  pre.smalllisp    { font-size:smaller }
  span.sc    { font-variant:small-caps }
  span.roman { font-family:serif; font-weight:normal; } 
  span.sansserif { font-family:sans-serif; font-weight:normal; } 
@font-face {
    font-family: 'CFE_FONT';
    src: url('fonts/eot/opensans-regular-webfont.eot');
    src: local('â˜º'),  url('fonts/ttf/opensans-regular-webfont.ttf') format('truetype'), url('fonts/svg/opensans-regular-webfont.svg') format('svg');
    font-weight: normal;
    font-style: normal;
}    
pre {
    background-color: #EEFFDD;
    border: 1px solid #CCCCCC;
    font-family: courier;
    margin-bottom: 10px;
    margin-top: 10px;
    padding: 5px;
    font-size: 90%;
    }
pre.display { font-family:inherit }
pre.format  { font-family:inherit }
pre.smallexample
pre.smalllisp,
pre.smallformat,
pre.smalldisplay {
  font-size: 90%;
} 

span.sc    { font-variant:small-caps }
span.roman { font-family:serif; font-weight:normal; } 
span.sansserif { font-family:sans-serif; font-weight:normal; } 

body {
    font:  90%  'CFE_FONT', arial, Helvetica,sans-serif; 
    color: #646464;
    padding: 10px 20px;
    width: 960px;
    margin: 0 auto;
}
.node
{
    text-align: right;
    padding: 2px;
    font-size: smaller;
}
.node hr {
    border: 0;
    width: 100%;
    color: #CCC;
    background-color: #CCC;
    height: 5px;
}
.section {
    padding-right: 0px;
    padding-bottom: 0px;
    padding-left: 0px;
}

h1 {
    font-size: 26px;
    font-weight: normal;
    line-height: 32px;
    margin: 32px 0 16px;
    text-align: left;
    text-transform: uppercase;
}

h2 {
    color: #9E9981 !important;
    font-size: 16px;
    line-height: 18px;
    font-weight: normal;
    margin: 16px 0 26px;
    text-align: left;
}
h3 {
    margin-top: 3px;
    margin-right: 0px;
    margin-bottom: 10px;
    margin-left: 0px;
    line-height: 20px;
    font-size: 16px;
    font-weight: normal;
}

.contents
{
    background-color: #CCC;
    padding-top: 2px;
    padding-right: 2px;
    padding-bottom: 2px;
    padding-left: 10px;
}

.index-cp
{  
background: #fff url(index-cp.png) right repeat-y;
}

.index-vr
{  
background: #fff url(index-vr.png) right repeat-y;
}

.index-mb
{  
background: #eee url(index-faq.png) right repeat-y;
}

table.border
{
	border-color: #666;
	border-width: 0px;
}

FONT.liten {font-size: 80%; }
 
.tynn {
    font-family: Arial, Helvetica, sans-serif;
    font-size: smaller;
    font-style: normal;
    font-weight: lighter;
    margin-bottom: 0em;
    font-size: 11pt;
}
.verbatim {
    color: #000;
    margin-top: 0px;
    margin-right: 0px;
    margin-bottom: 20px;
    margin-left: 0px;
}
.example {
    color: #000;
    width: 100%;
    margin-top: 0px;
    margin-right: 0px;
    margin-bottom: 20px;
    margin-left: 0px;
}
.smallexample {
    color: #000;
    padding-top: 10px;
    padding-right: 30px;
    padding-bottom: 5px;
    padding-left: 30px;
    margin-top: 0px;
    margin-right: 0px;
    margin-bottom: 0px;
    margin-left: 0px;
}
.cartouche {
    padding: 5px;
    font-style: italic;
    font-size: 85%;
}

table.cartouche {
    border: none !important;
}

 .cartouche td  {
    background-color: #ddd;
    border: 1px solid #ccc;
    padding: 5px;
}

A:link { color: #2c2e70 }
A:visited { color: black }
A:active { color: #600041 }
dt em {font-weight: bold}
/* don't change this rule */    
pre.sp {
    background: none !important;   
    border:none !important
}
/* --- */
/*code hightlight*/
.red { color: #b80047; font-weight: bold; }

.blue { color: blue;  /*font-weight: bold;*/ }

.green { color: darkgreen; }

.comment { font-style: italic; }
--></style>
</head>
<body>
<h1 class="settitle">Scale and Scalability</h1>
<div class="node">
<a name="Top"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Principles-of-scalability">Principles of scalability</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#dir">(dir)</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#dir">(dir)</a>

</div>

<h2 class="unnumbered">Scalability</h2>

   <p><a href="#Contents"><h1>COMPLETE TABLE OF CONTENTS</h1></a>
<h2>Summary of contents</h2>

<ul class="menu">
<li><a accesskey="1" href="#Principles-of-scalability">Principles of scalability</a>
<li><a accesskey="2" href="#Scalable-policy-strategy">Scalable policy strategy</a>
<li><a accesskey="3" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>
</ul>

<div class="node">
<a name="Principles-of-scalability"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Scalable-policy-strategy">Scalable policy strategy</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Top">Top</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Top">Top</a>

</div>

<h2 class="chapter">1 Principles of scalability</h2>

<pre class="sp">

</pre>

<ul class="menu">
<li><a accesskey="1" href="#What-is-scalability_003f">What is scalability?</a>
<li><a accesskey="2" href="#How-does-CFEngine-address-scale_003f">How does CFEngine address scale?</a>
<li><a accesskey="3" href="#What-does-scalability-depend-on_003f">What does scalability depend on?</a>
<li><a accesskey="4" href="#A-product-strategy-for-scaling">A product strategy for scaling</a>
<li><a accesskey="5" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>
<li><a accesskey="6" href="#Unexpected-risks-of-scaling">Unexpected risks of scaling</a>
</ul>

<div class="node">
<a name="What-is-scalability%3f"></a>
<a name="What-is-scalability_003f"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#How-does-CFEngine-address-scale_003f">How does CFEngine address scale?</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Principles-of-scalability">Principles of scalability</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.1 What is scalability?</h3>

<pre class="sp">

</pre>

By scalability we mean the intrinsic capacity of a system to
handle growth. Growth in a system can occur in three ways: by the volume of input
the system must handle, or in the total size of its infrastructure,
and by the complexity of the processes within it.

   <p>For a system to be called scalable, growth should proceed unhindered,
i.e. the size and volume of processing may expand without
significantly affecting the average service level per node.

   <p>Although most of us have an intuitive notion of what scalability
means, a full understanding of it is a very complex issue, mainly
because there are so many factors to take into account. One factor
that is often forgotten in considering scalability, is the human
ability to <i>comprehend</i> the system as it grows. Limitations of
comprehension often lead to over-simplification and
lowest-common-denominator standardization. This ultimately causes systems
to fail due to an information deficit.

   <pre class="sp">

</pre>

<div class="node">
<a name="How-does-CFEngine-address-scale%3f"></a>
<a name="How-does-CFEngine-address-scale_003f"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#What-does-scalability-depend-on_003f">What does scalability depend on?</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#What-is-scalability_003f">What is scalability?</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.2 How does CFEngine address scale?</h3>

<pre class="sp">

</pre>
   <pre class="sp">

</pre>
<p><table class="cartouche" summary="cartouche" border="1"><tr><td>
CFEngine is a decentralized (or federated) agent-based system, with no single point of
failure. It uses integrated Knowledge Management to present
comprehensible views of how infrastructure complies with user intentions. 
</td></tr></table>

   <pre class="sp">

</pre>

In this Special Topics Guide, we take a simple approach to gauging the
scalability of CFEngine, considering the worst case scalability of
the software as a management system for typical environments
and network models.

<div class="node">
<a name="What-does-scalability-depend-on%3f"></a>
<a name="What-does-scalability-depend-on_003f"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#A-product-strategy-for-scaling">A product strategy for scaling</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#How-does-CFEngine-address-scale_003f">How does CFEngine address scale?</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.3 What does scalability depend on?</h3>

<pre class="sp">

</pre>

CFEngine's scalability is not only a function of the CFEngine
software, but also of the environment in which it operates and the
choices that are made. Some relevant environmental factors include:
     <ul>
<li>The capacity of the network. 
<li>The capacity of the server that supplies common information to agents. 
<li>The extent to which parallelism can be employed during updates (Amdahl's law). 
<li>The size and cost of the tasks carried out by the management system (in time and resources). 
<li>The social contract between users and parts of an organization (don't forget
that you are really dealing with a human-computer system). 
</ul>

<p class="noindent">For managers, there are several challenges to scaling that go beyond the
infrastructure:

     <ul>
<li>The ability to express and comprehend <i>necessary complexity and variation</i> in policy. 
<li>The ability to process the result (agent efficiency). 
<li>The ability for a significant number of people to understand the result (comprehension). 
</ul>

   <p>CFEngine does all processing of configuration policy at the
destination node (i.e. on the affected system). There is no
centralization of computation. CFEngine Nova adds fault-tolerant
multi-node orchestration, in which any node's state can
be made available to other nodes on request.

   <p>In general, reliance on common or centralized information will limit
the inherent scalability of the system. However, through opportunistic
use of caching, CFEngine is able to avoid single points of reliance. 
CFEngine's asynchronous promise model makes the impact of resource sharing less significant.

<div class="node">
<a name="A-product-strategy-for-scaling"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#What-does-scalability-depend-on_003f">What does scalability depend on?</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.4 A product strategy for scaling</h3>

<pre class="sp">

</pre>

As our product names suggest, CFEngine's scaling behaviour follows an
`astronomical' hierarchy of scales. Our product range
     <ul>
<li>Nova
<li>Constellation
<!-- @item Galaxy. -->
</ul>
   have been chosen to model different issues of
scale that occur in systems as they grow from tens to tens of
thousands of machines. As indicated above, dealing with scale is not
just about machine capacity, but also about knowledge management and
comprehension.

   <p>A <i>Nova</i> installation is designed around a single star
configuration (like a solar system) in which the hub machine is the
star and the managed entities are the planets.  Special planets can
have their own satellites (customized environments within the single
point of control), so this model does not imply complete uniformity.

   <p>A <i>Constellation</i> is designed around multiple star
configurations and is designed for cases where it is desirable to
maintain several points of control or independently managed
entities. This is also called a federation of star networks. The
reason for choosing this kind of architecture may or may not have to
do with service capacity (i.e. for coping with a large number
of systems): sometimes knowledge management and
responsibilities scale better with federation.

   <pre class="sp">

</pre>
<div align="center"><img src="nova_const.png" alt="nova_const.png"></div>
<div align="center">From a Nova star network to a Constellation of star networks.</div>
   <pre class="sp">

</pre>

<div class="node">
<a name="A-user-strategy-for-scaling"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Unexpected-risks-of-scaling">Unexpected risks of scaling</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#A-product-strategy-for-scaling">A product strategy for scaling</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.5 A user strategy for scaling</h3>

<p>This section proposes a simple method for evaluating capacity and scalability
at a site. You will need some numbers in order to do some simple calculations.

     <ul>
<li>Identify the key scales and constraints of your organization.
          <ul>
<li>How many distinct environments or requirement sets do you have? 
<li>How many machines (managed units) are there? 
<li>What frequency of system state checking is desired (certainty about policy, or control resolution)? 
</ul>
     </ul>

<p class="noindent">You will be able to use these numbers in the next chapter to work out how far a
simple star network configuration (Nova starburst) will go in supporting requirements. 
An environment that consists of multiple environments, or very large size will have
to be handled as a constellation configuration.

<ul class="menu">
<li><a accesskey="1" href="#Scalable-CFEngine-architecture">Scalable CFEngine architecture</a>
<li><a accesskey="2" href="#Layout-guidelines-for-scalability">Layout guidelines for scalability</a>
</ul>

<div class="node">
<a name="Scalable-CFEngine-architecture"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Layout-guidelines-for-scalability">Layout guidelines for scalability</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>

</div>

<h4 class="subsection">1.5.1 Scalable CFEngine architecture</h4>

<p>Several architectural principles aid the ability to scale to large size:
     <ul>
<li><b>Patchwork coverage and federated centres</b>:
Most architectures have some kind of central point of change or control, but
too much centralization leads to bottlenecks that hinder throughput (see
the Special Topics Guide on Federation and Organizational Complexity). 
Build a federated architecture from the beginning, i.e. a number of hubs or
star networks that each covers the requirements for the most local environment. 
Do not try to make one single model that applies to everything (Grand Unification
is an unstable process).

     <li><b>Necessary and sufficient complexity</b>:
Do not oversimplify issues to avoid multiple environments. Delegation is cheap
and is mainly an issue of trust. Delegation (decentralization) is a key principle of scaling
as it avoids concentration of resources and single points of failure.

     <li><b>Don't over-constrain systems</b>:
It is wise to avoid configuration rules and requirements that are not necessary, as
this can impact systematically on the resources needed to scale. 
Similarly, don't waste time creating perfect container classes for rules. Rough patches
are cheap to maintain &ndash; precision targeting costs resource logic.

     <li><b>Autonomy &ndash; avoid strong dependence</b>:
If systems depend strongly on other systems (i.e. a failure of one
leads to a failure of the other), then one creates fragility. Robust,
fault tolerant systems avoid interval coupling or dependencies
as these can lead to cascade failures.

     <li><b>Strive for efficiency</b>:
Management is not free, but one does not generally account for the
overhead when designing production systems. In the next chapter, we
shall show how to make rough estimates about network requirements for
management. As a rule of thumb, a site engineer needs to avoid
clogging the network with traffic, and burying systems in CPU or
memory intensive work.

   </ul>

<div class="node">
<a name="Layout-guidelines-for-scalability"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Scalable-CFEngine-architecture">Scalable CFEngine architecture</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>

</div>

<h4 class="subsection">1.5.2 Layout guidelines for scalability</h4>

<p>The picture of a federated architecture is that of a number of smaller
star networks loosely rather than tightly integrated together. This
loose coupling avoids rigidity that can cause cascade failure.

   <p>This schematic architecture does not answer where these centres will be
located however. Will the division into local centres be based on
geography, departmental lines, or some other virtual view of the organization?

   <p><table class="cartouche" summary="cartouche" border="1"><tr><td>
It does not matter from an architectural point of view what criteria are used for
dividing up an organization. The main criteria is the environment itself. If we think
in terms of promises for a moment, a strong group culture forms when members of
a community make a lot of promises to one another. Organizational entities are
therefore clusters of promises. This might or might not coincide with
naming of institutional entities. 
</td></tr></table>

   <p>It is easy to understand the reason for a promise-oriented approach to
scalability.  Clusters of promises are also clusters where
communication is likely to be required and take place. Since
scalability is enhanced by limiting the amount and scope of
communication, the clusters of promises mark out the areas (sub-networks, if you
like) where communication is necessary. This makes for a natural encapsulation
of policy issues.

     <ul>
<li>Model the organization (focusing on business-level issues)
<li>Give names to the parts
<li>Identify patterns
<li>Form a disciplined protocol (best practice)
</ul>

<div class="node">
<a name="Unexpected-risks-of-scaling"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#A-user-strategy-for-scaling">A user strategy for scaling</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Principles-of-scalability">Principles of scalability</a>

</div>

<h3 class="section">1.6 Unexpected risks of scaling</h3>

<pre class="sp">

</pre>
     <ul>
<li><b>Division of labour =&gt; fragmentation of knowledge</b>:
When problems are management intensive, the need to divide and conquer problems
leads to points of failure.

     <li><b>Turnover of staff</b>:
Too much specialization of roles means that individuals attain mission
critical positions that lead to single points of failure for
operations.  When key employees leave the organization, this damages
operations due to loss of expertise. The cost of this lies in
retraining, or even redesign.  All roles should have redundancy both
for quality assurance and failover, and strong Knowledge Management
is required to avoid this scenario.

     <li><b>Morale</b>:
When engineers feel powerless, they are demoralized and feel unimportant. 
This can lead to both disgruntlement and power-hogging. This is a failure of the
social contract.

     <li><b>Scale reduces certainty</b>:
The larger a system, the less detail human decision-makers can know
about the whole.

   </ul>

<!-- ************************************************************************ -->
<div class="node">
<a name="Scalable-policy-strategy"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Principles-of-scalability">Principles of scalability</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Top">Top</a>

</div>

<h2 class="chapter">2 Scalable policy strategy</h2>

<pre class="sp">

</pre>

<ul class="menu">
<li><a accesskey="1" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>
<li><a accesskey="2" href="#Performance-impact-of-promises">Performance impact of promises</a>
<li><a accesskey="3" href="#Avoiding-network-traffic">Avoiding network traffic</a>
<li><a accesskey="4" href="#Defining-classes">Defining classes</a>
<li><a accesskey="5" href="#Copernicus-Knowledge-Map">Copernicus Knowledge Map</a>
<li><a accesskey="6" href="#System-Tuning-and-Hub-Optimization">System Tuning and Hub Optimization</a>
</ul>

<div class="node">
<a name="Policy-guidelines-for-comprehension"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Performance-impact-of-promises">Performance impact of promises</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Scalable-policy-strategy">Scalable policy strategy</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.1 Policy guidelines for comprehension</h3>

<p>Part of the challenge of scale is comprehension. If every computer is identical, this is no problem, but
when there is real growth in complexity scale can lead to a case of information and comprehension overload. 
Checking that growth of complexity requires some user discipline.

<ul class="menu">
<li><a accesskey="1" href="#Strategy-for-scaling-policy">Strategy for scaling policy</a>
<li><a accesskey="2" href="#Tactics-for-scaling-policy">Tactics for scaling policy</a>
<li><a accesskey="3" href="#Caching-classes-that-are-expensive-to-compute">Caching classes that are expensive to compute</a>
</ul>

<div class="node">
<a name="Strategy-for-scaling-policy"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Tactics-for-scaling-policy">Tactics for scaling policy</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>

</div>

<h4 class="subsection">2.1.1 Strategy for scaling policy</h4>

<p>What if you have written down 250,000 promises to keep? How can you manage that? Here are some tips:

     <ul>
<li><b>Don't have 250,000 promises</b>. If your conception of the problem is
this complicated, then CFEngine is not your problem. Management will
fail by its own overheads unless it can slim down problems to
<i>necessary and sufficient</i> complexity. Over-constrained systems
usually fail eventually because they become overwhelmed by the problem
of unintentionally conflicting requirements. Keep it simple.

     <p>If you are migrating from CFEngine 2, then many of your separate promises
can be turned into a single promise by using lists and other patterns. 
This will drastically improve the modelling capabilities and reduce the
complexity of the policy.

     <li><b>Divide up your management problem and delegate</b> to autonomous
entities that can manage their own pieces. It does not matter how
you divide up your organization (geographically, logically, by department, by
application team, etc) the important thing is to spread the load of
responsibility. <b>Who proposes the promises to be kept.</b>

     <p>The criterion for dividing up the organization is to make the entities
as autonomous as possible, i.e. with as few dependencies or communication
requirements as possible. The configurations for each autonomous entity
should be kept and managed locally by those entities, and not mixed together. 
Centralization is the enemy of scaling.

   </ul>
   When writing the CFEngine bundles of promises, you will need to use a
`meta-model' to organize the bundles. This is part of a Knowledge
Management (comprehension) strategy. Your best friend here is someone
with didactic or pedagogical skills, as he/she will maintain the
visibility of high level goals throughout the technical
challenges. Your worst enemy is a technician with his head in the
machine, who will drag everyone down to the machine components, where goals
and challenges are incomprehensible.

     <ul>
<li><b>Start by modelling your business challenges</b>, not technical solutions. For example,
name bundles by service
<pre class="verbatim">     bundle agent service_email
</pre>
     not by configuration file:
<pre class="verbatim">     bundle agent etc_conf_postfix
</pre>
     Even a non-expert should be able to see what these bundles are for, even if they don't
understand their detailed content.

     <li><b>Focus on the broad strokes</b>. Don't micro-manage details that are not necessary.

     <li><b>Seek stability and predictability</b> of your system before turning your attention to
other details. If you don't have predictability, you have nothing. This will keep you
away from a focus on unhealthy technical detail.

     <li><b>Keep promise descriptions at a high level</b> as far as possible, and use the Copernicus
Knowledge Map to locate low level resources and the promises they make.

     <li><b>Use </b><i>patterns</i><b> to model similar configuration issues</b> as a single promise iterated
over the pattern, not as many individual promises. This allows you to compress a large
number of issues into a small amount of text. The ability to comprehend patterns is
also central to human understanding, as it shows the principles or allows
us to <i>`see the general in the particular, or the eternal in the transitory'</i>. 
</ul>

<div class="node">
<a name="Tactics-for-scaling-policy"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Caching-classes-that-are-expensive-to-compute">Caching classes that are expensive to compute</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Strategy-for-scaling-policy">Strategy for scaling policy</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>

</div>

<h4 class="subsection">2.1.2 Tactics for scaling policy</h4>

<p>In writing policy, the thing most often forgotten by technicians is explaining <i>why</i> decisions
have been made.
     <ul>
<li><b>Give meaningful (high level, or even goal oriented) names</b> to collections of
promise attributes. e.g. instead to writing <code>perms =&gt; m("0600")</code>, try writing
something that allows readers to understand the <i>reason</i> for the intention: <code>perms =&gt;write standard_permissions</code>.

     <li><b>Use comments to explain</b> why the promise is the way it is. e.g. write
<pre class="verbatim">       comment => "This file needs to be writable by the web server 
                 else application XYZ breaks"
</pre>
     instead of
<pre class="verbatim">       comment => "Set permissions on the temp directory"
</pre>

     <li><b>Encourage good practice in the policy authors</b>. Check whether objects have made other
promises elsewhere, and try to document the connections. If a policy
have dependencies, encode these (see `Best practice for writing promises' in the Reference manual).

     <li>When solving problems, think about how to model the data. For example,
one way to model groups is to try to classify the names in lists
<pre class="verbatim">     "group" slist => { 
                      classify("a.domain.com"), 
                      classify("b.domain.com"), 
                      .....4000x...
                      };
</pre>
This is neat, and easy to read but it requires CFEngine to process
a list linearly, which becomes increasingly inefficient and can take several
seconds if a list contains thousands of hosts. Some improvement can be obtained
by converting the domain strings manually:
<pre class="verbatim">     "group" slist => { 
                      "a_domain_com", 
                      "b_domain_com", 
                      .....4000x...
                      };
</pre>
However, the linear scaling is still present.

     <p>In this case, it is inefficient to process the list
in memory, because we only need one out of thousands of the
entries, thus it makes sense to prune the list in advance.

     <p>To handle this, we can create a flat file of data in the format
"hostname:group" using the builtin function <code>getfields()</code> to read
one line from the file. 
<pre class="verbatim">     vars:
      "match_name" int => getfields("a.domain.com:.*","/my/file",":","group_data");
     
     classes:
      "$(group_data[2])" expression => isgreaterthan("$(match_name)","0");;
     
</pre>

     <p>This assumes, of course, that each host is in
one and only one class context. The saving in processing is large,
however, as it can be carried out directly in the input buffer. 
Only one out of thousands of lines thus needs to be processes. 
Although the scaling is still linear in search, the allocation and read
processes are heavily optimized by block device reading and much lower
overhead.

     <p>A module could also be used to the same effect to define the appropriate class
context.

   </ul>

<div class="node">
<a name="Caching-classes-that-are-expensive-to-compute"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Tactics-for-scaling-policy">Tactics for scaling policy</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>

</div>

<h4 class="subsection">2.1.3 Caching classes that are expensive to compute</h4>

<p>As of version 3.4.0 of the CFEngine core, persistent classes can be
used to construct a simple time-saving caching of classes
that depend on very large amounts of data. 
This feature can be used to avoid recomputing expensive classes
calculations on each invocation. If a class discovered is essentially
constant or only slowly varying (like a hostname or alias from a
non-standard naming facility)

   <p>For example, to create a conditional inclusion of costly class
definitions, put them into a separate bundle in a file <samp><span class="file">classes.cf</span></samp>.
<pre class="verbatim"># promises.cf

body common control 
{
cached_classes::
  bundlesequence => { "test" };

!cached_classes::
  bundlesequence => {  "setclasses", "test" };

!cached_classes::
  inputs => { "classes.cf" };
}
 

bundle agent test
{
reports:

  !my_cached_class::
   "no cached class";

  my_cached_class::
    "cached class defined";
}
 
</pre>
Then create <samp><span class="file">classes.cf</span></samp>
<pre class="verbatim"># classes.cf

bundle common setclasses
{
classes:

  "cached_classes"            # timer flag 
         expression => "any",
        persistence => "480";

  "my_cached_class" 
                or => { ...long list or heavy function... } ,
       persistence => "480";

}

</pre>

<div class="node">
<a name="Performance-impact-of-promises"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Avoiding-network-traffic">Avoiding network traffic</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Policy-guidelines-for-comprehension">Policy guidelines for comprehension</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.2 Performance impact of promises</h3>

<p>In a large system it is natural to expect a large number of
promises. This makes the location of a specific promise difficult. The
Copernicus Knowledge Map is a key strategy for locating promises.

     <ul>
<li>Using a very large number of bundles will have a performance impact,
as a local environment has to be established for each bundle.

     <li>Using a large number of different input files can have a
performance impact during file updating, as each file requires a
bi-directional verification involving network traffic. The frequency
of policy updates can be limited
          <ul>
<li>Test systems &ndash; can update relatively often since there are
fewer test machines, and their resources are less important than
production machines. 
<li>Production &ndash; fewer changes need to be made since most
delta changes have been aggregated through the testing phase. 
</ul>

     <li>There is no performance impact involved in having multiple
promise-type sections, e.g. <code>files:</code> in a bundle. However,
splitting up type-sections makes human readability harder. 
</ul>

<div class="node">
<a name="Avoiding-network-traffic"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Defining-classes">Defining classes</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Performance-impact-of-promises">Performance impact of promises</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.3 Avoiding network traffic</h3>

<p>Connecting to a CFEngine server process is one of the most time consuming activities
in centralized updating. Every bidirectional query that has to be made
adds latency and processing time the limits scalability. The connection time
and data transfer size during checking for updates can be minimized by making
use of the <samp><span class="file">cf_promises_validated</span></samp> cache file on the server. This file
summarizes whether it is necessary to search for file updates (a search that
can take a significant number of seconds per client). Since most checks do not
result in a required update, this cache file can save a large amount of
network traffic.

<pre class="smallexample">     files:
     
      "$(inputs_dir)/cf_promises_validated"
          comment =&gt; "Check whether new policy update to reduce the distributed load",
           handle =&gt; "check_valid_update",
        copy_from =&gt; u_dcp("$(master_location)/cf_promises_validated","$(sys.policy_hub)"),
           action =&gt; u_immediate,
          classes =&gt; u_if_repaired("validated_updates_ready");
     
     am_policy_hub|validated_updates_ready::
     
      "$(inputs_dir)"
          comment =&gt; "Copy policy updates from master source on policy server if a new validation was acquired",
           handle =&gt; "update_files_inputs_dir",
        copy_from =&gt; u_rcp("$(master_location)","$(sys.policy_hub)"),
     depth_search =&gt; u_recurse("inf"),
     file_select  =&gt; u_input_files,
       depends_on =&gt; { "grant_access_policy", "check_valid_update" },
           action =&gt; u_immediate,
          classes =&gt; u_if_repaired("update_report");
     
</pre>
   <div class="node">
<a name="Defining-classes"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Copernicus-Knowledge-Map">Copernicus Knowledge Map</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Avoiding-network-traffic">Avoiding network traffic</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.4 Defining classes</h3>

<p>Modelling environments with classes is a powerful strategy for knowledge management,
and is therefore encouraged.

<div class="node">
<a name="Copernicus-Knowledge-Map"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#System-Tuning-and-Hub-Optimization">System Tuning and Hub Optimization</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Defining-classes">Defining classes</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.5 Using the Copernicus Knowledge Map</h3>

<p>The Copernicus Knowledge Map is an integral part of the commercial CFEngine products. 
It is also a feature that is developing rapidly as part of the CFEngine commitment to
research and development. 
It forms a browsable `mental model' of relationships
between promises, goals and documents that describe them (including
the manuals and other documentation sources). The map provides you with
an overview of how parts of your policy relate to one another, and to other
high level parts of your environment.

     <ul>
<li>Shows where and when promises are relevant. 
<li>Gives contextual meaning to promises and other issues by showing you their impact on both practical and abstract issues. 
<li>Offers commentary in a browsable and user friendly form. 
<li>How promises relate to business goals. 
<li>Dependencies between promises. 
<li>Overview of promise bundles and their contents. 
<li>Browsable view of promises and their relationships. 
<li>Browsable view of body parts in expanded form. 
<li>Examples of code usage. 
</ul>

   <p>Use the knowledge map to:
     <ul>
<li>Find conflicts of policy. 
<li>Avoid repetition. 
<li>Understand relevance and impact. 
</ul>

<div class="node">
<a name="System-Tuning-and-Hub-Optimization"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Copernicus-Knowledge-Map">Copernicus Knowledge Map</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Scalable-policy-strategy">Scalable policy strategy</a>

</div>

<h3 class="section">2.6 System Tuning and Hub Optimization</h3>

<p>CFEngine uses MongoDB as its repository of information for each Nova and Constellation hub. 
The performance of a hub depends on the combination of hardware and software. The CFEngine
hub falls under the category or role of database server, and this requires fairly specific
optimizations. For example, NUMA architecture processing is known to lead to severe
processing bottlenecks on database servers, and so NUMA kernel modules should be switched off. 
Below are some of the optimizations that should be looked into for the CFEngine hubs.

<ul class="menu">
<li><a accesskey="1" href="#Tuning-the-linux-kernel-for-thousands-of-hosts">Tuning the linux kernel for thousands of hosts</a>
<li><a accesskey="2" href="#Tuning-the-MongoDB-for-thousands-of-hosts">Tuning the MongoDB for thousands of hosts</a>
</ul>

<div class="node">
<a name="Tuning-the-linux-kernel-for-thousands-of-hosts"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Tuning-the-MongoDB-for-thousands-of-hosts">Tuning the MongoDB for thousands of hosts</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#System-Tuning-and-Hub-Optimization">System Tuning and Hub Optimization</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#System-Tuning-and-Hub-Optimization">System Tuning and Hub Optimization</a>

</div>

<h4 class="subsection">2.6.1 Tuning the linux kernel for thousands of hosts</h4>

<p>Although CFEngine communicates with the Mongo database over a local socket, it
still uses TCP as its connection protocol and is therefore subject to kernel
optimizations.

   <p>Every write and read connection to the Mongo database makes a kernel
TCP connection. With the extreme density of connections, this is
somewhat like a high volume webserver. The standard `play safe' kernel
settings are too conservative for this kind of performance. The main
bottleneck eventually becomes the FIN_WAIT timeout, which leaves file descriptors
occupied and non-recyclable for too long. We recommend
reducing this waiting time to free up descriptors faster:

<pre class="verbatim">echo "1024 61000" > /proc/sys/net/ipv4/ip_local_port_range
echo "5" > /proc/sys/net/ipv4/tcp_fin_timeout
</pre>
This will clear old connections faster, allowing new ones be created and old threads to terminate faster.

<div class="node">
<a name="Tuning-the-MongoDB-for-thousands-of-hosts"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Tuning-the-linux-kernel-for-thousands-of-hosts">Tuning the linux kernel for thousands of hosts</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#System-Tuning-and-Hub-Optimization">System Tuning and Hub Optimization</a>

</div>

<h4 class="subsection">2.6.2 Tuning the MongoDB for thousands of hosts</h4>

<p>Some points to consider when scaling the MongoDB:
     <ul>
<li>Indexing is a very important factor for scaling any database. 
CFEngine Nova automatically checks and the creates indices needed for
scale as part of the schedule of <code>cf-hub</code>. The incices are
checked every six hours.

     <p>However, if the database schema changes, which may happen during
upgrades of CFEngine Nova, the indices may have been changed as
well. In large-scale environment we may not have time to wait up to
six hours for the indices to get repaired, so this can be done
manually by running the following command on the hub.

     <pre class="verbatim">     /var/cfengine/bin/cf-hub --index
</pre>

     <p>Please make sure <code>cf-hub</code> is not running in the background while
indices are being created, as this may slow the system down
considerably under high load.

     <li>For installations of one or two thousand hosts per hub, one approaches
the throughput limitations of x86 hardware and the Mongo database. One
can expect to see MongoDB writes dominating the system
resources. MongoDB does extensive caching'in RAM, so maximizing
installed RAM is an important strategy &ndash; however disk access priorities
will also play a role.

     <p>To make sure that server connection performance does not suffer as a result
of aggressive database writing, we can lower the priority of the MongoDB
process
<pre class="verbatim">     ionice -c2 -n0 /var/cfengine/bin/mongod 
</pre>
     or, using the PID
<pre class="verbatim">     ionice -c2 -n0 -p PID
</pre>

     <li>If the MongoDB database is located on the same disk as the last-seen
database (as is default under <samp><span class="file">/var/cfengine</span></samp>, there will be
contention between last-seen and mongodb updates, which can slow down
both processes unnecessarily. Ideally, these
should be separate disks with independent queues, even independent
controllers. RAID configurations can also slow down performance, so
only hardware RAID should be considered.

     <li>Non-Uniform Memory Access (NUMA) hardware
works poorly with all databases. If your server uses such hardware,
you should try to switch off this feature to improve write stability. 
NUMA tries to bind memory to specific cores for speed, but in doing so it
can prevent free allocation of memory and lead to paging and swapping, thereafter
thrashing as the system grinds to a halt. Processes become CPU bound as threads
attempt to work around the memory manegement constraints, and performance worses
by a factor of ten or more.

     <p>Some users report that using this approach is sufficient:
<pre class="verbatim">     numactl --interleave=all /var/cfengine/bin/mongod # (other args)
     echo 0 > /proc/sys/vm/zone_reclaim_mode
</pre>
     However, in our experience, only removing the kernel modules
supporting NUMA and rebooting the kernel will solve the NUMA contention issue.

     <p>Setting:
<pre class="verbatim">     numa=off
</pre>
     in the kernel boot parameters, e.g. in <samp><span class="file">grub.conf</span></samp>:

     <p><table class="cartouche" summary="cartouche" border="1"><tr><td>
     <pre class="smallexample">          # grub.conf generated by anaconda
          #
          # Note that you do not have to rerun grub after making changes to this file
          # NOTICE:  You do not have a /boot partition.  This means that
          #          all kernel and initrd paths are relative to /, eg.
          #          root (hd0,0)
          #          kernel /boot/vmlinuz-version ro root=/dev/sda1
          #          initrd /boot/initrd-version.img
          #boot=/dev/sda
          default=0
          timeout=5
          splashimage=(hd0,0)/boot/grub/splash.xpm.gz
          hiddenmenu
          title MY Linux Server (2.6.32-100.26.2.el5uek)
            root (hd0,0)
            kernel /boot/vmlinuz-2.6.32-100.26.2.el5 ro root=/dev/sda1 rhgb quiet <b>numa=off</b>
            initrd /boot/initrd-2.6.32-100.26.2.el5.img
</pre>
     </td></tr></table>

     <li>Finally, <code>splaytime</code> on the client nodes will help to spread out
the incoming connections over the update interval of the hub. The hub
defaults to 5 minute updates, so a complete update of policy should be
spread over less than or equal to the same scheduled cycle time. Alternatively the cycle
for policy updates can be extended and the splaying can be even longer.

     <pre class="verbatim">     
     body executor control
     {
     splaytime => "4";
     }
     
</pre>

   </ul>

<!-- ************************************************************************ -->
<div class="node">
<a name="Internal-and-external-scalability-of-the-software"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Scalable-policy-strategy">Scalable policy strategy</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Top">Top</a>

</div>

<h2 class="chapter">3 Internal and external scalability of the software</h2>

<pre class="sp">

</pre>
Scalability is about the internal and external architecture of the
system, and the way that information flows around the highways and
bottlenecks within it. As a distributed system, some of those are
internal to the software, and some lie in the way it is used.

   <p>CFEngine allows users to build any external architecture, so the only
intrinsic limitations are those internal to the software itself. Poor
decisions about external architecture generally lead to greater
problems that the internal limitations.

   <p>A number of techniques are used internally to bring efficiency and hence
scalability in relation to policy.
     <dl>
<dt><i>Hashing and indexing</i><dd>are used in many ways to coordinate system without the need for communication. 
By basing decisions on the predefined and publicly available information about
a node (like its name and address), we avoid having to pass messages between
nodes. 
<br><dt><i>Classifying of patterns</i><dd>is used to model patterns of similarity and difference in the intentions for a system. 
By describing policy for different categories of system parts, rather than for
each individual part by name, we can reduce the amount of information we need to
specify.

     <br><dt><i>Persistent locking of execution</i><dd>is used to place limits on the frequency and concurrency of operations undertaken
by CFEngine. Using the <code>ifelapsed</code> timers on each promise, one can say how
often work-intensive checks are made.

     <br><dt><i>Lazy evaluation</i><dd>is a common approach to efficiency, but it is difficult to achieve
in a dynamic environment. Necessary complexity makes for necessary work. 
CFEngine uses best-effort lazy evaluation to reduce processing, but errs on the side
of correctness, reliability and security. 
</dl>

   <pre class="sp">

</pre>
<p><table class="cartouche" summary="cartouche" border="1"><tr><td>
The greatest challenge for scalability is to reduce functional
requirements to a description or model that uses patterns
(i.e. general rules) to compress only what needs to be said about the
policy into a comprehensible form. It is about identifying a
<i>necessary and sufficient</i> level of complexity without
over-simplification, and it is about not having to specify things that
don't need to be specified. This is Knowledge Management. 
</td></tr></table>

   <pre class="sp">

</pre>

<ul class="menu">
<li><a accesskey="1" href="#Best-case-approach-to-external-scalability">Best case approach to external scalability</a>
<li><a accesskey="2" href="#Failover-and-redundancy">Failover and redundancy</a>
<li><a accesskey="3" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>
<li><a accesskey="4" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>
<li><a accesskey="5" href="#Redundancy-and-load-balancing-in-the-Nova-hub">Redundancy and load balancing in the Nova hub</a>
</ul>

<div class="node">
<a name="Best-case-approach-to-external-scalability"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Failover-and-redundancy">Failover and redundancy</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>

</div>

<h3 class="section">3.1 Best case approach to external scalability</h3>

<pre class="sp">

</pre>

In the most scalable approach to management, each agent works 100%
autonomously as a standalone system, requiring no communication with
its peers, or with a central agency. Its policy is therefore constant
and fixed.

   <p>If this model suits your organization, the operation of CFEngine is
completely independent of the number of machines, so it exhibits
<i>perfect scaling</i> with respect to the size of the infra-structure. 
However, this model is too simple for most sites, and its value lies
in documenting the extreme end of the scalability scale, as an ideal to
work towards when striving for efficiency.

<div class="node">
<a name="Failover-and-redundancy"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Best-case-approach-to-external-scalability">Best case approach to external scalability</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>

</div>

<h3 class="section">3.2 Failover and redundancy</h3>

<p>As a self-healing system, CFEngine poses a low risk to loss of data. Most management
data that are lost in an incident will recover automatically.

     <dl>
<dt><i>Failover due to unavailability.</i><dd>
The loss of a hub is not a critical failure in a CFEngine managed
network. Client machines continue to work with the last known version
of policy until a hub returns to `online' status.  During updates,
hubs can come under load. To avoid this, splaying options should be
used primarily<a rel="footnote" href="#fn-1" name="fnd-1"><sup>1</sup></a>. 
CFEngine's failover servers for file-copying can be set up to offer
immediate redundancy.

     <br><dt><i>Shared storage for </i><samp><span class="file">/var/cfengine/masterfiles</span></samp><i>.</i><dd>
The only place where shared storage makes sense is between the main
policy server (hub) and any failover servers. In that case only this
one directory can be shared.

     <br><dt><i>Backup of </i><samp><span class="file">/var/cfengine</span></samp><i>.</i><dd>
It is not strictly necessary to have a backup of the CFEngine work directory, but
keeping a backup of this for the hub can save time when restoring a broken hub,
since the records of known clients are stored in this workspace, and the current
status of reports is also stored.

     <p>On clients, this workspace can be considered disposable, but many
users save public private key-pairs to preserve the `identity' of
hosts that have merely disk failures, etc.

     <br><dt><i>Multiple reporting hubs.</i><dd>
Although it is technically possible to have multiple reporting hosts,
this is recommended against. Multiple hubs will only increase the
overhead on all parts of the system for little return. 
</dl>

   <p>Our general recommendation is to introduce as few network
relationships as possible (make every system as autonomous as
possible). Shared storage is more of a liability than an asset in
general networks, as it increases the number of possible failure
modes. Backup of the hub workspace is desirable, but not a
show-stopper.

<div class="node">
<a name="A-simple-worst-case-approach-to-scalability---the-star-network"></a>
<a name="A-simple-worst-case-approach-to-scalability-_002d-the-star-network"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Failover-and-redundancy">Failover and redundancy</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>

</div>

<h3 class="section">3.3 A simple worst case approach to scalability: the star network</h3>

<pre class="sp">

</pre>

CFEngine 3 Nova is designed around the concept of a simple star network,
i.e.  a number of `client' machines bound together by a central hub. 
This is a commonly used architecture that is easy to understand. 
The hub architecture introduces a bottleneck, so we expect this to
have a limited scalability as long as we cannot increase the power and
the speed of the hub without limit.

   <p>To understand the external scalability of CFEngine management, we
shall estimate how large a CFEngine system can grow using simple
centralized management, in this star network pattern. This will force
us to confront low level performance characteristics, where we try to
extract the most from limited resources.

   <p>In a star network, all agents connect to a central hub to obtain
possibly frequent updates. The challenge is to optimize this
process<a rel="footnote" href="#fn-2" name="fnd-2"><sup>2</sup></a>.  This makes the central hub into a bottleneck. It
becomes the weakest link in the chain of information, i.e. the star network has
limitations that are nothing to do with CFEngine itself. The counterpoint
is that the star network is very easy to comprehend, and thus it usually forms
the starting point for most management frameworks.

   <pre class="sp">

</pre>
<div align="center"><img src="hub.png" alt="hub.png"></div>
<div align="center">Centralized management with a hub.</div>
   <pre class="sp">

</pre>
   <pre class="sp">

</pre>
<p><table class="cartouche" summary="cartouche" border="1"><tr><td>
In the Community edition of CFEngine, updates travel only in one
direction, from server to client. CFEngine Nova, adds to this the
collection of data for reporting and analysis (CFDB), from client to
hub. Thus the expected load on the server is the sum of both
processes. 
</td></tr></table>

   <pre class="sp">

</pre>

   <p>We would like to answer two equivalent questions. Given a central hub
with certain limitations, how many clients can it support? Conversely,
given a number of hosts to support with a single hub, what capacity
is required in system infrastructure to support it at a certain level?

   <p>There are actually two independent issues here. There is the scaling
of the policy updates (served by the hub) and the scaling of the
reporting updates (collected by the hub). Both of these processes compete
for resources.

<ul class="menu">
<li><a accesskey="1" href="#Typical-CFEngine-scales">Typical CFEngine scales</a>
<li><a accesskey="2" href="#Scaling-of-updates">Scaling of updates</a>
<li><a accesskey="3" href="#Limitations-on-the-CFDB-hub-database">Limitations on the CFDB hub database</a>
<li><a accesskey="4" href="#Update-storms">Update storms</a>
</ul>

<div class="node">
<a name="Typical-CFEngine-scales"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Scaling-of-updates">Scaling of updates</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>

</div>

<h4 class="subsection">3.3.1 Typical CFEngine scales</h4>

<p>We start by setting some fundamental scales.

     <ul>
<li>The interval at which policy and reporting updates are checked (\Delta t = 5 mins or 300s). 
<li>The expected worst size of an update (U \le 5 MB per host). 
<li>The amount of RAM available on the server (M = 1 GB).. 
<li>The resident size of a thread or server process (s \le 12 MB). 
<li>The maximum available network capacity for management processes (C \ge 1 MB/s). 
</ul>

   <p>We choose deliberately a low value for network capacity. Even if more
capacity is available, one does not typically expect to use it all for
management overhead.

<div class="node">
<a name="Scaling-of-updates"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Limitations-on-the-CFDB-hub-database">Limitations on the CFDB hub database</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Typical-CFEngine-scales">Typical CFEngine scales</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>

</div>

<h4 class="subsection">3.3.2 Scaling of updates</h4>

<p>To a first approximation, the process scaling relationships are linear, as long as
we stay far away from the region of resource contention at which a server
will typically perform very quickly. Scalability is thus about having safe margins
for worst case behaviour.

   <p>The number of threads t supported by a server satisfies:
   <pre class="sp">

</pre>
<pre class="display">                                                     st \le M
</pre>
   <pre class="sp">

</pre>
and yields a value for t, given fixed values for the hub's RAM
and software build size. 
For a server with 1GB of memory, we have t \le 1024/12 \sim 80 threads. 
This will consume U \le 1MB of data per agent for a community host, and
U\le 5MB for Nova to account for reporting.

   <p>The expected time-to-update \tau_\rm round satisfies:
   <pre class="sp">

</pre>
<pre class="display">                                        U_\rm min/C \le \tau_\rm round\le U_\rm max/C
</pre>
   <pre class="sp">

</pre>
The actual values will normally by significantly less than this worst case,
but he must plan for the possibility of update storms. 
The network capacity C = 1MBs^-1 suggests an expected
time-to-update \tau_\rm round \le 2s (there and back) with a
server-processing overhead. 
We shall take a conservative value of
\tau_\rm round \le 10s for the maximum round trip request time.

   <p>Let's consider the policy/reporting update process, as this dominates
the scaling behaviour of the software in terms of number of machines. 
Assuming that we can arrange for agents to distribute their updates
over a single time interval \Delta t, with maximum possible
entropy<a rel="footnote" href="#fn-3" name="fnd-3"><sup>3</sup></a>,
then we should be able to achieve a maximum number of scheduling
slots \sigma:
   <pre class="sp">

</pre>
<pre class="display">                                        \sigma = \Delta t/\tau_\rm round
</pre>
   <pre class="sp">

</pre>
Since the round-trip time can be higher or lower, depending on the size of the
update, we can propose some approximate limits. 
\sigma_\max = 300/2, \sigma_\min = 300/10 per interval \Delta t.
   <pre class="sp">

</pre>

The total number of updates that can complete in the \Delta t
interval is thus, at fixed t:
   <pre class="sp">

</pre>
<pre class="display">                                         N = \sigma t = \Delta t \over \tau_\rm roundt
</pre>
   <pre class="sp">

</pre>
If there are now t threads, then the total number of
updates available must lie between the upper and lower bounds determined by \sigma:

   <pre class="sp">

</pre>
<pre class="display">                                          2400 \le N \le 12,000.
</pre>
   <pre class="sp">

</pre>

So we can gauge a reasonable lower bound of 2000 machines from a single hub,
with extremely conservative estimates of the environment. Note that
when exceeding several thousands connections over a short time
interval, other limitations of the operating system will normally
start to play a role, e.g. the maximum number of allowed file
descriptors. Further, comprehending a system of more than a few thousand
machines is a challenge unless the system is extremely uniform.

   <p>In making each of these estimates, we are assuming that the hub machine will be working
almost to capacity. Increasing its resources will naturally lead to improvements
in performance.

<!-- ******************************************************************** -->
<div class="node">
<a name="Limitations-on-the-CFDB-hub-database"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Update-storms">Update storms</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Scaling-of-updates">Scaling of updates</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>

</div>

<h4 class="subsection">3.3.3 Limitations on the CFDB hub database</h4>

<p>A `star network' architecture has a single concentration
of processing, centred around registration of incoming and outgoing hosts on the hub. 
Read/write activity is focused on two databases:

     <ul>
<li>The last-seen database that records the current IP addresses of known clients
to the hub, accessed every time a host connects or is connected to the hub. 
<li>The document database where reports are stored (using MongoDB), accessed each time
an update is stored,  or when a user makes a query. 
</ul>

   <p>The scalablity of the hub depends on how efficiently reads and writes
can be parallelized to these databases. Even with aggressive cachine,
databases are disk-intensive and since disk access is typically the
slowest or weakest link in the data flow chain, disk accesses will
throttle the scalability of the hub the most.

   <p>CFEngine tries to support efficient parallelization by using
multiple threads to serve and collect data, however access to a
shared resource must always be serialized, so ultimately serial access to the
disk will be the limiting factor. The CFEngine hub supports Linux
systems. Simple SATA disks, USB and Firewire have very limited performance. 
To achieve the maximum scaling limit of a few thousand hosts per hub,
users can invest in faster interfaces and disk speeds, or even solid state
disk devices.

   <p>Because of the serialization, a heavily loaded MongoDB will eat up most of the
resources on the hub, dominating the performance. Some performance tuning option
strategies are discussed below. Clearly maximizing the amount of RAM on the
hub is a way to improve the performance.

   <p>The time estimates for host updating used above include the latency of
this database, but it is possible that there might be additional
delays once the amount of data passes a certain limits.  We currently
have no data to support this assumption and await customer experiences
either way.

   <p>Lookup times for data in the reports database increase with the number
of host-keys, so the time required to generate certain reports
(especially when searching through logs) must increase as the number
of hosts increases.

<!-- ******************************************************************** -->
<div class="node">
<a name="Update-storms"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Limitations-on-the-CFDB-hub-database">Limitations on the CFDB hub database</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>

</div>

<h4 class="subsection">3.3.4 Update storms</h4>

<p>When changes are made, many hosts will start downloading updated
files. This can have a sudden impact on the network, as a lot of
unexpected traffic is suddenly concentrated over a short interval of
time. The contention from these multiple downloads can therefore make
each download longer than it otherwise might have been, and this in
turn makes the problem worse. The situation is analogous to disk
thrashing.

   <p><table class="cartouche" summary="cartouche" border="1"><tr><td>
Once thrashing has started, it can cause greatly reduced performance
and hosts might pass their `blue horizon threshold', appearing to
disappear from the CFEngine Mission Portal. This does not mean the
hosts are dead or even `out of control'. It only means that updates
are taking too long according the tuning parameters. The default
update horizon is. 
</td></tr></table>

<!-- ******************************************************************** -->
<div class="node">
<a name="Optimizations-affecting-scalability"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Redundancy-and-load-balancing-in-the-Nova-hub">Redundancy and load balancing in the Nova hub</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">A simple worst case approach to scalability - the star network</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>

</div>

<h3 class="section">3.4 Optimizations affecting scalability</h3>

<pre class="sp">

</pre>

<ul class="menu">
<li><a accesskey="1" href="#The-role-of-caching-and-indexing">The role of caching and indexing</a>
<li><a accesskey="2" href="#Deterministic-queue">Deterministic queue</a>
<li><a accesskey="3" href="#Push-versus-pull">Push versus pull</a>
</ul>

<div class="node">
<a name="The-role-of-caching-and-indexing"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Deterministic-queue">Deterministic queue</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>

</div>

<h4 class="subsection">3.4.1 The role of caching and indexing</h4>

<p>To assist the speed of policy processing by <code>cf-agent</code>, choose
class names evenly throughout the alphabet to make searching easier. 
CFEngine arranges for indexing and cachine to be performed automatically.

<div class="node">
<a name="Deterministic-queue"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Push-versus-pull">Push versus pull</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#The-role-of-caching-and-indexing">The role of caching and indexing</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>

</div>

<h4 class="subsection">3.4.2 Deterministic queue</h4>

<div class="node">
<a name="Push-versus-pull"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Deterministic-queue">Deterministic queue</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>

</div>

<h4 class="subsection">3.4.3 Push versus pull</h4>

<div class="node">
<a name="Redundancy-and-load-balancing-in-the-Nova-hub"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Optimizations-affecting-scalability">Optimizations affecting scalability</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Internal-and-external-scalability-of-the-software">Internal and external scalability of the software</a>

</div>

<h3 class="section">3.5 Redundancy and load balancing in the Nova hub</h3>

<p>CFEngine does not <i>need</i> a `high availability' architecture to be an
effective management system. The software was designed to work with
very low availability, and the designers highly recommend avoiding the
introduction of dependencies that require such availability. In normal
operation, CFEngine will be able to continue to repair systems without
any contact with the outside world, until actual policy changes are
made.

   <p>It is nonetheless possible to balance load and account for failures by
multiplying the number of hubs/policy servers in a Nova star
network. This only makes sense for the policy servers and reporting
hubs, which are in principle single points of failure.

     <ul>
<li>Availability of policy in case of policy server failure. 
<li>Availability of reports in case of reporting hub failure. 
</ul>
   Because CFEngine is a pull-based technology, the two processes look
like this:
     <ul>
<li>Satellite `client' nodes pull policy from a policy server. 
<li>Reporting hubs pull reports from all satellite clients. 
</ul>
   In both cases, the processes are `self-healing'. If a client is unable
to connect to a policy server, it will continue to work with its old
policy until the policy server becomes available again. If a report
hub fails and reports are no longer accessible, no data are lost
because the actual data are sourced from the satellite nodes. When the
hub is replaced or restored, it will update and continue as before.

<ul class="menu">
<li><a accesskey="1" href="#Balancing-multiple-policy-servers">Balancing multiple policy servers</a>
<li><a accesskey="2" href="#Redundant-reporting-hubs-and-recovery">Redundant reporting hubs and recovery</a>
</ul>

<div class="node">
<a name="Balancing-multiple-policy-servers"></a>
<p><hr>
Next:&nbsp;<a rel="next" accesskey="n" href="#Redundant-reporting-hubs-and-recovery">Redundant reporting hubs and recovery</a>,
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Redundancy-and-load-balancing-in-the-Nova-hub">Redundancy and load balancing in the Nova hub</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Redundancy-and-load-balancing-in-the-Nova-hub">Redundancy and load balancing in the Nova hub</a>

</div>

<h4 class="subsection">3.5.1 Balancing multiple policy servers</h4>

<p>A simple way to balance client hosts across multiple servers is to split them into classes
using the <code>select_class</code> function<a rel="footnote" href="#fn-4" name="fnd-4"><sup>4</sup></a>. Nothing else is needed to spread computers evenly
into a set of named buckets.
<pre class="verbatim">classes:

  "selection" select_class => { "bucket1", "bucket2" };

</pre>
This selects a particular class for each host from the list. A given
host will always map to the same class, thus allowing the rule for
policy updates to include copying from a personal `bucket' server.
<pre class="verbatim">body copy_from xyz
{
...

bucket1::
     servers     => { "server-abc-1.xyz.com", "failover.xyz.com"  };
bucket2::
     servers     => { "server-abc-2.xyz.com", "failover.xyz.com"  };

...
}
</pre>

   <p>Note this method is not suitable for bootstrapping hosts in a hub
configuration, since that requires a one to one relationship documented
in the <samp><span class="file">/var/cfengine/policy_server.dat</span></samp> resource.

<div class="node">
<a name="Redundant-reporting-hubs-and-recovery"></a>
<p><hr>
Previous:&nbsp;<a rel="previous" accesskey="p" href="#Balancing-multiple-policy-servers">Balancing multiple policy servers</a>,
Up:&nbsp;<a rel="up" accesskey="u" href="#Redundancy-and-load-balancing-in-the-Nova-hub">Redundancy and load balancing in the Nova hub</a>

</div>

<h4 class="subsection">3.5.2 Redundant reporting hubs and recovery</h4>

<p>A CFEngine reporting hub is a host that aggregates reports from all
managed hosts in a Nova starburst cluster. The purpose of aggregating
reports is to have all the information in one place for searching,
calibrating and comparing. The loss of a hub is an inconvenience
rather than a problem, as the function of a hub is to make access to
information about the system convenient and to enhance the knowledge of
users.

     <ul>
<li>The loss of a hub will not impact the correctness of host configurations. 
<li>A hub will never come under heavy query load, so there is no need for load balancing. 
<li>Running multiple hubs on the same set of hosts will only lead to network contention
and increased overhead. 
<li>If a hub serves so many computers that updating the reports becomes a burden,
then you have probably already passed the point at which it makes sense to divide up
your management into multiple hubs. CFEngine Constellation can provide a total viewpoint
in a scenario with multiple hubs. 
</ul>
   Dividing hosts into multiple hubs should be a decision based on the absence of
the `need to know' for all hosts. By splitting the aggregation up into multiple
hubs, one jettisons the function of the hub which is to aggregate information. 
The should normally be done in conjunction with a decision about knowledge boundaries
in your organization.

   <p>It makes sense to back up some information from a reporting hub. 
Hub information is considered to be a mixture of two kinds of data:
     <ul>
<li>Cached information for data-mining, whose original source is the client from which it was collected. 
Such information may be collected again if lost, and thus there is no need to back it up. 
It can, of course, be backed up for convenience. 
<li>Original comments and hand-entered data about systems that are entered by users of the Mission Portal. 
These data should be backed up as they cannot be recovered from any other source. 
</ul>
   In addition to these, the hub makes use of the `last seen' database of
known hosts in order to know where to collect data from. For rapid
recovery after a data-loss catastrophe, it is recommended to back up
this database also.

   <pre class="sp">

</pre>
<div align="center"><img src="hubs.png" alt="hubs.png"></div>
<div align="center">Some data can be backed up from a hub for convenience.</div>
   <pre class="sp">

</pre>

The procedure for backing up the ephemeral data is:
     <ul>
<li>Mongo collections can be dumped to an intermediary format, though this is impractical
for large installations.

     <li>For embedded databases, it is sufficient to copy the binary object:
<pre class="verbatim">     cp /var/cfengine/cf_lastseen.db  /backup
</pre>

   </ul>

   <p><a name="Contents">
   <div class="contents">
<h2>Table of Contents</h2>
<ul>
<li><a name="toc_Top" href="#Top">Scalability</a>
<li><a name="toc_Principles-of-scalability" href="#Principles-of-scalability">1 Principles of scalability</a>
<ul>
<li><a href="#What-is-scalability_003f">1.1 What is scalability?</a>
<li><a href="#How-does-CFEngine-address-scale_003f">1.2 How does CFEngine address scale?</a>
<li><a href="#What-does-scalability-depend-on_003f">1.3 What does scalability depend on?</a>
<li><a href="#A-product-strategy-for-scaling">1.4 A product strategy for scaling</a>
<li><a href="#A-user-strategy-for-scaling">1.5 A user strategy for scaling</a>
<ul>
<li><a href="#Scalable-CFEngine-architecture">1.5.1 Scalable CFEngine architecture</a>
<li><a href="#Layout-guidelines-for-scalability">1.5.2 Layout guidelines for scalability</a>
</li></ul>
<li><a href="#Unexpected-risks-of-scaling">1.6 Unexpected risks of scaling</a>
</li></ul>
<li><a name="toc_Scalable-policy-strategy" href="#Scalable-policy-strategy">2 Scalable policy strategy</a>
<ul>
<li><a href="#Policy-guidelines-for-comprehension">2.1 Policy guidelines for comprehension</a>
<ul>
<li><a href="#Strategy-for-scaling-policy">2.1.1 Strategy for scaling policy</a>
<li><a href="#Tactics-for-scaling-policy">2.1.2 Tactics for scaling policy</a>
<li><a href="#Caching-classes-that-are-expensive-to-compute">2.1.3 Caching classes that are expensive to compute</a>
</li></ul>
<li><a href="#Performance-impact-of-promises">2.2 Performance impact of promises</a>
<li><a href="#Avoiding-network-traffic">2.3 Avoiding network traffic</a>
<li><a href="#Defining-classes">2.4 Defining classes</a>
<li><a href="#Copernicus-Knowledge-Map">2.5 Using the Copernicus Knowledge Map</a>
<li><a href="#System-Tuning-and-Hub-Optimization">2.6 System Tuning and Hub Optimization</a>
<ul>
<li><a href="#Tuning-the-linux-kernel-for-thousands-of-hosts">2.6.1 Tuning the linux kernel for thousands of hosts</a>
<li><a href="#Tuning-the-MongoDB-for-thousands-of-hosts">2.6.2 Tuning the MongoDB for thousands of hosts</a>
</li></ul>
</li></ul>
<li><a name="toc_Internal-and-external-scalability-of-the-software" href="#Internal-and-external-scalability-of-the-software">3 Internal and external scalability of the software</a>
<ul>
<li><a href="#Best-case-approach-to-external-scalability">3.1 Best case approach to external scalability</a>
<li><a href="#Failover-and-redundancy">3.2 Failover and redundancy</a>
<li><a href="#A-simple-worst-case-approach-to-scalability-_002d-the-star-network">3.3 A simple worst case approach to scalability: the star network</a>
<ul>
<li><a href="#Typical-CFEngine-scales">3.3.1 Typical CFEngine scales</a>
<li><a href="#Scaling-of-updates">3.3.2 Scaling of updates</a>
<li><a href="#Limitations-on-the-CFDB-hub-database">3.3.3 Limitations on the CFDB hub database</a>
<li><a href="#Update-storms">3.3.4 Update storms</a>
</li></ul>
<li><a href="#Optimizations-affecting-scalability">3.4 Optimizations affecting scalability</a>
<ul>
<li><a href="#The-role-of-caching-and-indexing">3.4.1 The role of caching and indexing</a>
<li><a href="#Deterministic-queue">3.4.2 Deterministic queue</a>
<li><a href="#Push-versus-pull">3.4.3 Push versus pull</a>
</li></ul>
<li><a href="#Redundancy-and-load-balancing-in-the-Nova-hub">3.5 Redundancy and load balancing in the Nova hub</a>
<ul>
<li><a href="#Balancing-multiple-policy-servers">3.5.1 Balancing multiple policy servers</a>
<li><a href="#Redundant-reporting-hubs-and-recovery">3.5.2 Redundant reporting hubs and recovery</a>
</li></ul>
</li></ul>
</li></ul>
</div>



   <p><script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://
ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-
analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2576171-2");
pageTracker._initData();
pageTracker._trackPageview();
</script>

   <div class="footnote">
<hr>
<a name="texinfo-footnotes-in-document"></a><h4>Footnotes</h4><p class="footnote"><small>[<a name="fn-1" href="#fnd-1">1</a>]</small> We strongly recommend users to abandon the
idea that it is possible to have `instant' or `immediate'
updates. There is always some delay. It is more pragmatic to manage
that delay by making it predictable than to leave it to chance.</p>

   <p class="footnote"><small>[<a name="fn-2" href="#fnd-2">2</a>]</small> The estimates here are based on CFEngine core versions
3.1.2 and higher.</p>

   <p class="footnote"><small>[<a name="fn-3" href="#fnd-3">3</a>]</small> Maximum entropy means the most even or flat
distribution over the time interval, in this case. See, for instance,
Mark Burgess, <i>Analytical Network and System Administration</i>.</p>

   <p class="footnote"><small>[<a name="fn-4" href="#fnd-4">4</a>]</small> This feature was added in core 3.1.5.</p>

   <hr></div>

</body></html>

